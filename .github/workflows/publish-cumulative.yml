name: Publish cumulative exposure (from Dropbox)

on:
  schedule:
    - cron: "0 5 * * *"
  workflow_dispatch: {}

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: System libs for sf/gdal
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgdal-dev libgeos-dev libproj-dev libudunits2-dev jq curl

      - name: Install R packages
        run: |
          Rscript -e 'pkgs <- c("sf","dplyr","fs","purrr","jsonlite");
                      inst <- setdiff(pkgs, rownames(installed.packages()));
                      if(length(inst)) install.packages(inst, repos="https://cloud.r-project.org")'

      - name: Configure system for large data processing
        run: |
          echo "Configuring swap space for memory-intensive processing..."
          sudo fallocate -l 8G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          echo "Swap enabled:"
          free -h

      # ----------------------------------------------------------
      # Get fresh Dropbox access token
      # ----------------------------------------------------------
      - name: Get fresh Dropbox access token
        id: dropbox_token
        run: |
          set -euo pipefail
          TOKENS=$(curl -sS -X POST https://api.dropboxapi.com/oauth2/token \
            -d grant_type=refresh_token \
            -d refresh_token="${{ secrets.DROPBOX_REFRESH_TOKEN }}" \
            -u "${{ secrets.DROPBOX_APP_KEY }}:${{ secrets.DROPBOX_APP_SECRET }}")

          ACCESS=$(echo "$TOKENS" | jq -r '.access_token')
          echo "token=$ACCESS" >> "$GITHUB_OUTPUT"

      # ----------------------------------------------------------
      # Download ALL polygon snapshots from Dropbox
      # ----------------------------------------------------------
      - name: Download GeoJSON snapshots from Dropbox
        env:
          DROPBOX_TOKEN: ${{ steps.dropbox_token.outputs.token }}
        run: |
          set -eo pipefail

          mkdir -p data/daily

          extract_paths () {
            jq -r '
              .entries? // [] |
              map(select(.[".tag"] == "file")) |
              map(select(.name | test("^polygons_.*\\.geojson$"; "i"))) |
              .[].path_lower // empty
            '
          }

          echo "üìÇ Listing Dropbox folder recursively..."

          resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder \
            --header "Authorization: Bearer $DROPBOX_TOKEN" \
            --header "Content-Type: application/json" \
            --data '{"path": "", "recursive": true}')

          if echo "$resp" | jq -e '.error_summary?'; then
            echo "‚ùå Dropbox error on list_folder"
            exit 1
          fi

          extract_paths <<< "$resp" > /tmp/polygon_paths.txt
          
          echo "üìã Found $(wc -l < /tmp/polygon_paths.txt) polygon files"
          
          cursor=$(jq -r '.cursor // empty' <<< "$resp")
          has_more=$(jq -r '.has_more // false' <<< "$resp")

          while [ "$has_more" = "true" ]; do
            resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder/continue \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Content-Type: application/json" \
              --data "{\"cursor\":\"$cursor\"}")

            if echo "$resp" | jq -e '.error_summary?'; then
              echo "‚ùå Dropbox pagination error"
              exit 1
            fi

            extract_paths <<< "$resp" >> /tmp/polygon_paths.txt
            cursor=$(jq -r '.cursor // empty' <<< "$resp")
            has_more=$(jq -r '.has_more // false' <<< "$resp")
          done

          echo "‚¨áÔ∏è Downloading files..."

          if [ ! -s /tmp/polygon_paths.txt ]; then
            echo "‚ö†Ô∏è No polygon files found matching pattern"
            exit 1
          fi

          echo "üìÑ Sample of files to download:"
          head -n 3 /tmp/polygon_paths.txt

          downloaded=0
          failed=0

          sort -u /tmp/polygon_paths.txt | while read -r p; do
            [ -n "$p" ] || continue
            base=$(basename "$p")
            echo "Downloading $p -> data/daily/$base"
            
            if curl -sS -X POST https://content.dropboxapi.com/2/files/download \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"$p\"}" \
              --output "data/daily/$base"; then
              
              if [ -f "data/daily/$base" ]; then
                size=$(stat -c%s "data/daily/$base" 2>/dev/null || stat -f%z "data/daily/$base" 2>/dev/null || echo "0")
                echo "  ‚úì Saved: $base (${size} bytes)"
                downloaded=$((downloaded + 1))
              else
                echo "  ‚úó Failed: $base"
                failed=$((failed + 1))
              fi
            else
              echo "  ‚úó Download failed: $base"
              failed=$((failed + 1))
            fi
          done

          echo "‚úÖ Download complete: $(ls -1 data/daily 2>/dev/null | wc -l) files"
          echo "üìä Total size: $(du -sh data/daily 2>/dev/null | cut -f1)"
          
          # Verify we have files
          file_count=$(ls -1 data/daily/*.geojson 2>/dev/null | wc -l)
          if [ "$file_count" -eq 0 ]; then
            echo "‚ùå ERROR: No GeoJSON files downloaded!"
            exit 1
          fi
          
          echo "‚úì Verified: $file_count GeoJSON files ready for processing"

      # ----------------------------------------------------------
      # Build cumulative hex layer
      # ----------------------------------------------------------
      - name: Build cumulative hex layer
        run: |
          echo "=== Starting Hexagonal Grid Analysis ==="
          
          # Verify R script exists
          if [ ! -f "R/build_cumulative_hex.R" ]; then
            echo "‚ùå ERROR: R/build_cumulative_hex.R not found!"
            echo "Current directory: $(pwd)"
            echo "Directory contents:"
            ls -la
            echo "R directory contents:"
            ls -la R/ 2>/dev/null || echo "R/ directory does not exist"
            exit 1
          fi
          
          echo "‚úì R script found"
          echo "Running R script..."
          Rscript R/build_cumulative_hex.R
          
          exit_code=$?
          if [ $exit_code -ne 0 ]; then
            echo "‚ùå ERROR: R script failed with exit code $exit_code"
            exit $exit_code
          fi
          
          echo "Verifying outputs..."
          ls -lh public/
          
          if [ ! -f "public/outage_hex_grid.geojson" ]; then
            echo "‚ùå ERROR: GeoJSON output not found!"
            exit 1
          fi
          
          if [ ! -f "public/outage_hex_stats.csv" ]; then
            echo "‚ùå ERROR: CSV output not found!"
            exit 1
          fi
          
          if [ ! -d "public/shapefile" ]; then
            echo "‚ùå ERROR: Shapefile directory not found!"
            exit 1
          fi
          
          echo "‚úÖ All outputs verified successfully"

      # ----------------------------------------------------------
      # Deploy to public repo
      # ----------------------------------------------------------
      - name: Deploy to public repo (gh-pages)
        uses: peaceiris/actions-gh-pages@v3
        with:
          personal_token: ${{ secrets.PUBLIC_REPO_TOKEN }}
          external_repository: evelynebrie/hq-outages-public
          publish_branch: gh-pages
          publish_dir: public
          commit_message: "Update cumulative outage exposure - ${{ github.run_number }}"
