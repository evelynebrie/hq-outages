name: Publish cumulative exposure - FAST incremental

on:
  schedule:
    - cron: '30 3 * * *'
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: System libraries
        run: |
          sudo apt-get update
          sudo apt-get install -y libgdal-dev libgeos-dev libproj-dev libudunits2-dev jq curl

      # NEW: renv-based package management (much faster, more reliable)
      - name: Cache R packages (renv)
        uses: actions/cache@v3
        with:
          path: ~/.local/share/renv
          key: ${{ runner.os }}-renv-${{ hashFiles('**/renv.lock') }}
          restore-keys: |
            ${{ runner.os }}-renv-

      - name: Restore R package library
        run: |
          if [ ! -f "renv.lock" ]; then
            echo "No renv.lock found - creating one..."
            Rscript -e '
              if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")
              renv::init(bare = TRUE, restart = FALSE)
              renv::install(c("sf","dplyr","fs","purrr","jsonlite","data.table","lubridate"))
              renv::snapshot(prompt = FALSE)
            '
          else
            echo "Found renv.lock - restoring packages..."
            Rscript -e '
              if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")
              renv::restore(prompt = FALSE)
            '
          fi
          
          # Verify packages loaded correctly
          echo ""
          echo "Verifying packages:"
          Rscript -e '
            pkgs <- c("sf","dplyr","jsonlite","data.table","lubridate")
            status <- sapply(pkgs, function(p) {
              loaded <- suppressPackageStartupMessages(require(p, character.only=TRUE, quietly=TRUE))
              cat(sprintf("  %s %s\n", if(loaded) "‚úì" else "‚úó", p))
              loaded
            })
            if(!all(status)) stop("Some packages failed to load")
          '

      - name: Restore data cache
        uses: actions/cache@v3
        with:
          path: data/daily/
          key: hq-daily-data-${{ github.run_id }}
          restore-keys: hq-daily-data-

      - name: Restore daily summaries cache
        uses: actions/cache@v3
        with:
          path: public/daily_summaries/
          key: hq-daily-summaries-${{ github.run_id }}
          restore-keys: hq-daily-summaries-

      - name: Restore monthly summaries cache
        uses: actions/cache@v3
        with:
          path: public/monthly_summaries/
          key: hq-monthly-summaries-${{ github.run_id }}
          restore-keys: hq-monthly-summaries-

      - name: Restore hex grid cache
        uses: actions/cache@v3
        with:
          path: public/hex_grid_template.rds
          key: hq-hex-grid-v1
          restore-keys: hq-hex-grid-

      - name: Get Fresh Access Token
        id: get_token
        env:
          DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}
          DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}
          DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}
        run: |
          echo "Getting fresh access token from refresh token..."
          
          RESPONSE=$(curl -s -X POST https://api.dropbox.com/oauth2/token \
            -u "${DROPBOX_APP_KEY}:${DROPBOX_APP_SECRET}" \
            -d "grant_type=refresh_token&refresh_token=${DROPBOX_REFRESH_TOKEN}")
          
          ACCESS_TOKEN=$(echo "$RESPONSE" | jq -r '.access_token // empty')
          
          if [ -z "$ACCESS_TOKEN" ]; then
            echo "Failed to get access token. Response:"
            echo "$RESPONSE"
            exit 1
          fi
          
          echo "‚úÖ Successfully obtained fresh access token"
          echo "access_token=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Download NEW files from Dropbox
        env:
          DROPBOX_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          set -eo pipefail
          
          echo "Listing Dropbox files (with pagination support)..."
          
          ALL_FILES=""
          HAS_MORE=true
          CURSOR=""
          PAGE=1
          
          while [ "$HAS_MORE" = "true" ]; do
            echo "Fetching page $PAGE..."
            
            if [ -z "$CURSOR" ]; then
              RESPONSE=$(curl -s -X POST https://api.dropboxapi.com/2/files/list_folder \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Content-Type: application/json" \
                -d '{"path": "/hq-outages", "recursive": true}')
            else
              RESPONSE=$(curl -s -X POST https://api.dropboxapi.com/2/files/list_folder/continue \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Content-Type: application/json" \
                -d "{\"cursor\": \"$CURSOR\"}")
            fi
            
            if echo "$RESPONSE" | jq -e '.error' > /dev/null 2>&1; then
              echo "‚ùå Error from Dropbox API:"
              echo "$RESPONSE" | jq '.error'
              exit 1
            fi
            
            if ! echo "$RESPONSE" | jq -e '.entries' > /dev/null 2>&1; then
              echo "‚ùå Unexpected response format (no .entries field)"
              echo "$RESPONSE"
              exit 1
            fi
            
            PAGE_COUNT=$(echo "$RESPONSE" | jq '.entries | length')
            echo "  Found $PAGE_COUNT entries in page $PAGE"
            
            PAGE_FILES=$(echo "$RESPONSE" | jq -r '.entries[]? | select(.".tag" == "file") | .path_display' || true)
            
            if [ ! -z "$PAGE_FILES" ]; then
              if [ -z "$ALL_FILES" ]; then
                ALL_FILES="$PAGE_FILES"
              else
                ALL_FILES="$ALL_FILES"$'\n'"$PAGE_FILES"
              fi
            fi
            
            HAS_MORE=$(echo "$RESPONSE" | jq -r '.has_more')
            
            if [ "$HAS_MORE" = "true" ]; then
              CURSOR=$(echo "$RESPONSE" | jq -r '.cursor')
              PAGE=$((PAGE + 1))
            fi
          done
          
          echo ""
          echo "Completed pagination: fetched $PAGE page(s)"
          
          TOTAL_FILE_COUNT=0
          if [ ! -z "$ALL_FILES" ]; then
            TOTAL_FILE_COUNT=$(echo "$ALL_FILES" | wc -l)
          fi
          echo "Total files found: $TOTAL_FILE_COUNT"
          
          if [ -z "$ALL_FILES" ] || [ "$TOTAL_FILE_COUNT" -eq 0 ]; then
            echo "‚ö†Ô∏è  No files found in Dropbox"
            echo "‚úì Continuing with cached data..."
            mkdir -p data/daily
            exit 0
          fi
          
          POLYGONS=$(echo "$ALL_FILES" | grep "/polygons_.*\.geojson$" || true)
          
          POLY_COUNT=0
          if [ ! -z "$POLYGONS" ]; then
            POLY_COUNT=$(echo "$POLYGONS" | wc -l)
          fi
          
          echo "Found $POLY_COUNT polygon files"
          
          if [ $POLY_COUNT -gt 0 ]; then
            echo ""
            echo "Date range in files:"
            echo "$POLYGONS" | sed 's/.*polygons_\([0-9]\{8\}\).*/\1/' | sort -u | head -5 | while read date; do
              formatted="${date:0:4}-${date:4:2}-${date:6:2}"
              echo "  $formatted"
            done
            echo "  ..."
            echo "$POLYGONS" | sed 's/.*polygons_\([0-9]\{8\}\).*/\1/' | sort -u | tail -5 | while read date; do
              formatted="${date:0:4}-${date:4:2}-${date:6:2}"
              echo "  $formatted"
            done
          fi
          
          if [ "$POLY_COUNT" -eq 0 ]; then
            echo "‚ö†Ô∏è  No polygon files found"
            echo "‚úì Continuing with cached data..."
            mkdir -p data/daily
            exit 0
          fi
          
          mkdir -p data/daily
          
          CACHED=0
          NEW=0
          DOWNLOADED=0
          
          download_file() {
            local dropbox_path="$1"
            local filename=$(basename "$dropbox_path")
            local local_path="data/daily/$filename"
            
            if [ -f "$local_path" ]; then
              return 1
            else
              curl -s -X POST https://content.dropboxapi.com/2/files/download \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Dropbox-API-Arg: {\"path\": \"$dropbox_path\"}" \
                -o "$local_path"
              return 0
            fi
          }
          
          echo ""
          echo "Processing polygon files..."
          while IFS= read -r file; do
            [ -z "$file" ] && continue
            
            if download_file "$file"; then
              NEW=$((NEW + 1))
              DOWNLOADED=$((DOWNLOADED + 1))
              if [ $DOWNLOADED -le 5 ]; then
                echo "  Downloading: $(basename "$file")"
              elif [ $DOWNLOADED -eq 6 ]; then
                echo "  ... (showing first 5 downloads)"
              fi
            else
              CACHED=$((CACHED + 1))
            fi
          done <<< "$POLYGONS"
          
          echo ""
          echo "üìä Summary: $CACHED cached, $NEW new, $POLY_COUNT total files"
          echo "Files flattened into data/daily/ for R processing"

      - name: Run R analysis (incremental)
        run: |
          echo "Starting incremental analysis..."
          [ ! -f "R/build_cumulative_hex.R" ] && echo "ERROR: Script not found" && exit 1
          
          FILE_COUNT=$(find data/daily -name "polygons_*.geojson" 2>/dev/null | wc -l)
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "‚ö†Ô∏è  No polygon data files found to process"
            exit 1
          fi
          
          echo "Processing $FILE_COUNT polygon data files..."
          
          DAILY_SUMMARIES=$(find public/daily_summaries -name "*.rds" 2>/dev/null | wc -l || echo 0)
          MONTHLY_SUMMARIES=$(find public/monthly_summaries -name "*.rds" 2>/dev/null | wc -l || echo 0)
          
          echo "Found $DAILY_SUMMARIES existing daily summaries"
          echo "Found $MONTHLY_SUMMARIES existing monthly summaries"
          
          if [ $DAILY_SUMMARIES -gt 0 ]; then
            echo "‚úÖ Incremental mode: Will reuse existing summaries"
          else
            echo "üîÑ First run: Will build all summaries (this takes longer)"
          fi
          
          Rscript R/build_cumulative_hex.R

      # NEW: Commit renv.lock if it was created/updated
      - name: Commit renv.lock if changed
        run: |
          if [ -f "renv.lock" ]; then
            git config --local user.email "github-actions[bot]@users.noreply.github.com"
            git config --local user.name "github-actions[bot]"
            git add renv.lock
            git diff --staged --quiet || git commit -m "Update renv.lock [skip ci]"
            git push || echo "No changes to push"
          fi

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          keep_files: true
