name: Publish cumulative exposure (from Dropbox)

on:
  schedule:
    # around midnight Montreal (05:00 UTC works year-round)
    - cron: "0 5 * * *"
  workflow_dispatch: {}

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: System libs for sf/gdal
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgdal-dev libgeos-dev libproj-dev libudunits2-dev jq curl

      - name: Install R packages
        run: |
          Rscript -e 'pkgs <- c("sf","dplyr","fs","purrr");
                      inst <- setdiff(pkgs, rownames(installed.packages()));
                      if(length(inst)) install.packages(inst, repos="https://cloud.r-project.org")'

      # --- Pull ALL polygon snapshots from Dropbox into data/daily ---
      - name: Download daily GeoJSONs from Dropbox
        env:
          DROPBOX_TOKEN: ${{ secrets.DROPBOX_TOKEN }}
        run: |
          set -euo pipefail
          mkdir -p data/daily

          # helper to extract only polygon files
          extract_paths () {
            jq -r '.entries[]
              | select(."\.tag"=="file")
              | select(.name | test("^polygons_.*\\.geojson$"))
              | .path_lower'
          }

          # initial listing (recursive)
          resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder \
            --header "Authorization: Bearer $DROPBOX_TOKEN" \
            --header "Content-Type: application/json" \
            --data '{"path": "/hq-outages", "recursive": true, "include_non_downloadable_files": false}')

          echo "$resp" | extract_paths > /tmp/polygon_paths.txt
          cursor=$(echo "$resp" | jq -r '.cursor')
          has_more=$(echo "$resp" | jq -r '.has_more')

          # pagination
          while [ "$has_more" = "true" ]; do
            resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder/continue \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Content-Type: application/json" \
              --data "{\"cursor\":\"$cursor\"}")
            echo "$resp" | extract_paths >> /tmp/polygon_paths.txt
            cursor=$(echo "$resp" | jq -r '.cursor')
            has_more=$(echo "$resp" | jq -r '.has_more')
          done

          sort -u /tmp/polygon_paths.txt | while read -r p; do
            [ -n "$p" ] || continue
            base=$(basename "$p")
            echo "Downloading $p -> data/daily/$base"
            curl -sS -X POST https://content.dropboxapi.com/2/files/download \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"$p\"}" \
              --output "data/daily/$base"
          done

          echo "Fetched $(ls -1 data/daily | wc -l) files into data/daily"

      - name: Build cumulative hex layer
        run: Rscript R/build_cumulative_hex.R

      # --- Publish artifacts to your PUBLIC repo via Pages (gh-pages) ---
      - name: Deploy to public repo (gh-pages)
        uses: peaceiris/actions-gh-pages@v3
        with:
          personal_token: ${{ secrets.PUBLIC_REPO_TOKEN }}     # PAT with Contents RW on the public repo
          external_repository: <YOUR_USERNAME>/hq-outages-public
          publish_branch: gh-pages
          publish_dir: public
          commit_message: "Update cumulative outage exposure"
