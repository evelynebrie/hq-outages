name: Publish cumulative exposure

on:
  schedule:
    # ~00:00 America/Toronto across DST (two crons covers both offsets)
    - cron: "55 4 * * *"   # ~23:55 ET (winter)
    - cron: "55 3 * * *"   # ~23:55 ET (summer)
  workflow_dispatch: {}

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      R_LIBS_USER: ~/.Rlib

    steps:
      - uses: actions/checkout@v4

      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: Cache R packages
        uses: actions/cache@v4
        with:
          path: ~/.Rlib
          key: r-lib-${{ runner.os }}-4.5-${{ hashFiles('**/*.R','**/*.yml') }}
          restore-keys: r-lib-${{ runner.os }}-4.5-

      - name: System libs for sf
        run: |
          sudo apt-get update
          sudo apt-get install -y libgdal-dev libgeos-dev libproj-dev libudunits2-dev jq curl

      - name: Install R packages
        run: |
          Rscript -e 'pkgs <- c("sf","dplyr","fs","purrr"); \
                      inst <- setdiff(pkgs, rownames(installed.packages())); \
                      if(length(inst)) install.packages(inst, repos="https://cloud.r-project.org")'

      - name: Pull ALL polygon GeoJSONs from Dropbox to data/daily
        env:
          DROPBOX_TOKEN: ${{ secrets.DROPBOX_TOKEN }}
        run: |
          set -euo pipefail
          mkdir -p data/daily

          extract_paths () {
            jq -r '.entries[]
              | select(."\.tag"=="file")
              | select(.name | test("^polygons_.*\\.geojson$"))
              | .path_lower'
          }

          resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder \
            --header "Authorization: Bearer $DROPBOX_TOKEN" \
            --header "Content-Type: application/json" \
            --data '{"path": "/hq-outages", "recursive": true, "include_non_downloadable_files": false}')

          echo "$resp" | extract_paths > /tmp/polygon_paths.txt
          cursor=$(echo "$resp" | jq -r '.cursor')
          has_more=$(echo "$resp" | jq -r '.has_more')

          while [ "$has_more" = "true" ]; do
            resp=$(curl -sS -X POST https://api.dropboxapi.com/2/files/list_folder/continue \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Content-Type: application/json" \
              --data "{\"cursor\":\"$cursor\"}")
            echo "$resp" | extract_paths >> /tmp/polygon_paths.txt
            cursor=$(echo "$resp" | jq -r '.cursor')
            has_more=$(echo "$resp" | jq -r '.has_more')
          done

          sort -u /tmp/polygon_paths.txt | while read -r p; do
            [ -n "$p" ] || continue
            base=$(basename "$p")
            echo "Downloading $p -> data/daily/$base"
            curl -sS -X POST https://content.dropboxapi.com/2/files/download \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"$p\"}" \
              --output "data/daily/$base"
          done

          echo "Local daily files:"; ls -1 data/daily | sed 's/^/  - /'

      - name: Build cumulative exposure layer
        run: Rscript R/build_cumulative_hex.R

      - name: Publish to GitHub Pages (gh-pages)
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: public
