name: HQ outages hourly

on:
  schedule:
    - cron: "0 * * * *"   # every hour (UTC)
  workflow_dispatch: {}    # allow manual trigger

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout repo
      - uses: actions/checkout@v4

      # 2️⃣ Setup R
      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      # 3️⃣ Cache R packages
      - name: Cache R packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/R
          key: r-lib-${{ runner.os }}-${{ hashFiles('**/*.R', '**/*.yml') }}
          restore-keys: |
            r-lib-${{ runner.os }}-

      # 4️⃣ System libraries (for httr, jsonlite, etc.)
      - name: System libs
        run: |
          sudo apt-get update && sudo apt-get install -y \
            libcurl4-openssl-dev libssl-dev libxml2-dev jq curl

      # 5️⃣ Run your R scraper
      - name: Run scraper
        run: Rscript hq_scrape.R

      # 6️⃣ Upload results to Dropbox
      - name: Upload to Dropbox
        env:
          DROPBOX_TOKEN: ${{ secrets.DROPBOX_TOKEN }}
        run: |
          for f in $(find data -type f); do
            # build remote path preserving folders
            remote="/hq-outages/${f#data/}"
            echo "Uploading $f -> $remote"
            curl -X POST https://content.dropboxapi.com/2/files/upload \
              --header "Authorization: Bearer $DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"$remote\", \"mode\": \"overwrite\"}" \
              --header "Content-Type: application/octet-stream" \
              --data-binary @"$f"
          done
