name: Diagnostic - Complete Data Analysis

on:
  workflow_dispatch:

jobs:
  diagnose:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: System libraries
        run: |
          sudo apt-get update
          sudo apt-get install -y libgdal-dev libgeos-dev libproj-dev libudunits2-dev jq curl

      - name: Install R packages
        run: |
          Rscript -e 'install.packages(c("sf", "data.table"), repos="https://cloud.r-project.org")'

      - name: Get Fresh Dropbox Access Token
        id: get_token
        env:
          DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}
          DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}
          DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}
        run: |
          echo "Getting fresh access token..."
          
          RESPONSE=$(curl -s -X POST https://api.dropbox.com/oauth2/token \
            -u "${DROPBOX_APP_KEY}:${DROPBOX_APP_SECRET}" \
            -d "grant_type=refresh_token&refresh_token=${DROPBOX_REFRESH_TOKEN}")
          
          ACCESS_TOKEN=$(echo "$RESPONSE" | jq -r '.access_token // empty')
          
          if [ -z "$ACCESS_TOKEN" ]; then
            echo "ERROR: Failed to get access token"
            echo "$RESPONSE" | jq '.'
            exit 1
          fi
          
          echo "Token obtained"
          echo "access_token=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Analyze Dropbox File Structure
        env:
          DROPBOX_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          echo "========================================="
          echo "DROPBOX FILE STRUCTURE ANALYSIS"
          echo "========================================="
          
          DROPBOX_PATH="/hq-outages-uploader-appfolder/hq-outages"
          echo "Listing files from: $DROPBOX_PATH"
          
          ALL_FILES=""
          HAS_MORE=true
          CURSOR=""
          PAGE=1
          
          while [ "$HAS_MORE" = "true" ] && [ $PAGE -le 5 ]; do
            echo "Page $PAGE..."
            
            if [ -z "$CURSOR" ]; then
              RESPONSE=$(curl -s -X POST https://api.dropboxapi.com/2/files/list_folder \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Content-Type: application/json" \
                -d "{\"path\": \"$DROPBOX_PATH\", \"recursive\": true}")
            else
              RESPONSE=$(curl -s -X POST https://api.dropboxapi.com/2/files/list_folder/continue \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Content-Type: application/json" \
                -d "{\"cursor\": \"$CURSOR\"}")
            fi
            
            if echo "$RESPONSE" | jq -e '.error' > /dev/null 2>&1; then
              echo "ERROR from Dropbox API:"
              echo "$RESPONSE" | jq '.'
              exit 1
            fi
            
            PAGE_FILES=$(echo "$RESPONSE" | jq -r '.entries[]? | select(.".tag" == "file") | .path_display' || true)
            
            if [ ! -z "$PAGE_FILES" ]; then
              if [ -z "$ALL_FILES" ]; then
                ALL_FILES="$PAGE_FILES"
              else
                ALL_FILES="$ALL_FILES"$'\n'"$PAGE_FILES"
              fi
            fi
            
            HAS_MORE=$(echo "$RESPONSE" | jq -r '.has_more')
            if [ "$HAS_MORE" = "true" ]; then
              CURSOR=$(echo "$RESPONSE" | jq -r '.cursor')
              PAGE=$((PAGE + 1))
            fi
          done
          
          echo "Retrieved file list"
          
          POLYGONS=$(echo "$ALL_FILES" | grep "/polygons_.*\.geojson$" || true)
          POLY_COUNT=$(echo "$POLYGONS" | wc -l 2>/dev/null | tr -d ' ')
          
          echo "Total polygon files: $POLY_COUNT"
          
          if [ "$POLY_COUNT" -eq 0 ]; then
            echo "ERROR: No polygon files found!"
            exit 1
          fi
          
          echo ""
          echo "FILES PER DATE:"
          echo "$POLYGONS" | sed 's/.*date=\([0-9-]*\).*/\1/' | sort | uniq -c | sort -rn | while read count date; do
            echo "  $date: $count files"
          done
          
          echo ""
          echo "HOUR DISTRIBUTION (sample date):"
          SAMPLE_DATE=$(echo "$POLYGONS" | sed 's/.*date=\([0-9-]*\).*/\1/' | sort -u | head -1)
          echo "  Date: $SAMPLE_DATE"
          echo "$POLYGONS" | grep "date=$SAMPLE_DATE" | sed 's/.*hour=\([0-9]*\).*/\1/' | sort -n | uniq -c | while read count hour; do
            printf "  Hour %02d: %d file(s)\n" $hour $count
          done
          
          echo "$POLYGONS" > /tmp/all_polygons.txt
          echo "========================================="

      - name: Download Sample Files
        env:
          DROPBOX_TOKEN: ${{ steps.get_token.outputs.access_token }}
        run: |
          echo "========================================="
          echo "DOWNLOADING SAMPLE FILES"
          echo "========================================="
          
          mkdir -p data/daily
          
          RECENT_DATES=$(cat /tmp/all_polygons.txt | sed 's/.*date=\([0-9-]*\).*/\1/' | sort -u | tail -2)
          
          DOWNLOADED=0
          FAILED=0
          
          for date in $RECENT_DATES; do
            echo "Date: $date"
            
            DATE_FILES=$(cat /tmp/all_polygons.txt | grep "date=$date" | head -30)
            
            for file in $DATE_FILES; do
              fname=$(basename "$file")
              
              if curl -s -f -X POST https://content.dropboxapi.com/2/files/download \
                -H "Authorization: Bearer $DROPBOX_TOKEN" \
                -H "Dropbox-API-Arg: {\"path\": \"$file\"}" \
                -o "data/daily/$fname" 2>/dev/null && [ -s "data/daily/$fname" ]; then
                
                ((DOWNLOADED++))
                [ $DOWNLOADED -le 5 ] && echo "  Downloaded: $fname"
              else
                rm -f "data/daily/$fname"
                ((FAILED++))
              fi
              
              if [ $DOWNLOADED -ge 50 ]; then
                break 2
              fi
            done
          done
          
          echo ""
          echo "Downloaded: $DOWNLOADED files"
          echo "Failed: $FAILED files"
          echo "========================================="

      - name: Analyze Source Files
        run: |
          echo "========================================="
          echo "SOURCE FILE ANALYSIS"
          echo "========================================="
          
          Rscript -e '
          suppressPackageStartupMessages(library(sf))
          suppressPackageStartupMessages(library(data.table))
          
          files <- list.files("data/daily", pattern = "^polygons_.*\\\\.geojson$", full.names = TRUE)
          
          if (length(files) == 0) {
            cat("ERROR: No files downloaded!\n")
            quit(status = 1)
          }
          
          cat(sprintf("Analyzing %d downloaded files\n\n", length(files)))
          
          basenames <- basename(files)
          timestamps <- regmatches(basenames, regexpr("\\\\d{8}t\\\\d{6}", basenames, ignore.case = TRUE))
          
          dates <- sprintf("%s-%s-%s", 
                          substr(timestamps, 1, 4), 
                          substr(timestamps, 5, 6), 
                          substr(timestamps, 7, 8))
          
          hours <- as.integer(substr(timestamps, 10, 11))
          
          files_dt <- data.table(
            file = files,
            date = dates,
            hour = hours
          )
          
          cat("FILES PER DATE:\n")
          files_per_date <- files_dt[, .N, by = date][order(-N)]
          print(files_per_date)
          
          cat("\nHOUR DISTRIBUTION:\n")
          hour_dist <- table(hours)
          print(hour_dist)
          
          cat("\nDIAGNOSTIC RESULTS:\n")
          max_files_per_date <- max(files_per_date$N)
          cat(sprintf("Files per date: max=%d\n\n", max_files_per_date))
          
          if (max_files_per_date == 1) {
            cat("PROBLEM: Only 1 file per date!\n")
            cat("Your hourly scraper is not running every hour.\n\n")
          } else if (max_files_per_date < 20) {
            cat(sprintf("WARNING: Only %d files per date\n", max_files_per_date))
            cat("Expected ~24 for full hourly coverage.\n\n")
          } else {
            cat(sprintf("GOOD: %d files per date\n", max_files_per_date))
            cat("Hourly scraping is working!\n\n")
          }
          '

      - name: Summary
        if: always()
        run: |
          echo "========================================="
          echo "DIAGNOSTIC SUMMARY"
          echo "========================================="
          echo ""
          echo "This diagnostic checked:"
          echo "  1. Dropbox connection"
          echo "  2. Source data quality"
          echo "  3. File distribution"
          echo ""
          echo "Review output above for:"
          echo "  - Files per date (should be 20-24)"
          echo "  - Hour distribution (0-23)"
          echo ""
          echo "========================================="
